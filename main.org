#+title: Assignment 2

#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [a4paper]
#+LATEX_CLASS_OPTIONS: [9pt,twocolumn]
#+LATEX_HEADER: \usepackage{algpseudocode}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{cleveref}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{pythonhighlight}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER_EXTRA:  \usepackage{mdframed}
#+LATEX_HEADER_EXTRA: \BeforeBeginEnvironment{minted}{\begin{mdframed}}
#+LATEX_HEADER_EXTRA: \AfterEndEnvironment{minted}{\end{mdframed}}
#+LATEX_HEADER_EXTRA: \newtheorem{theorem}{Theorem}
#+LATEX_HEADER_EXTRA: \DeclareMathOperator{\diag}{diag}
#+LATEX_HEADER_EXTRA: \theoremstyle{definition}
#+LATEX_HEADER_EXTRA: \newtheorem{definition}{Definition}[section]
#+OPTIONS: toc:nil
#+OPTIONS: num:nil


* Question 1

Given the following graph

#+BEGIN_SRC dot :file Question1_graph.png
graph auth {
rankdir=LR;
node [shape=record];
1 [label="1"]
2 [label="2"]
3 [label="3"]
4 [label="4"]
1 -- 2
1 -- 3
1 -- 4
2 -- 3
3 -- 4

}
#+END_SRC

#+RESULTS:
[[file:Question1_graph.png]]

Calculate all walks of size 6 in the given graph

** Answer
In order to do so we'll use the following theorem
#+name: theorem-walk
\begin{theorem} [ Walks Theorem ]
If A is the adjacency matrix of a graph or digraph G with vertices \( \{v1, . . . vn\} \), then the i, j entry
of \(A^k\) is the number of walks of length k from \(v_i\) to \(v_j\)
\end{theorem}

By [[theorem-walk][Walks Theorem]] we can just multiple the adjacency matrix by itself 6 times
and we'll get all the walks available from node i into node j

Since the problem specify undirected graph we'll have to sum all elements of the matrix and divide it by 2

\newpage
#+NAME: algo-walk
\begin{algorithm}
\caption{All walks of length 6 }
\begin{algorithmic}
\State \(n \gets 6 \) \Comment{6 => length of walk}
\State \( Adj  \) \Comment{adjacency matrix}
\State \( M \gets I \)
\While{ \(n \neq 0 \) }
\State \( M \gets M \times Adj \) \Comment{Matrix Multiples}
\EndWhile
\State \( sum \gets 0 \)
\While{ $a \in M $}
\State \( sum \gets sum + a \)
\EndWhile
\end{algorithmic}
\end{algorithm}

We will apply *algorithm* [[algo-walk]]  for getting the number of walk of length 6

#+name: calculate-walks
#+ATTR_LATEX: :environment python
#+begin_example python :session :results value :exports both
import numpy
from numpy.linalg import matrix_power
input_array = numpy.array([[0,1,1,1],
                           [1,0,1,0],
                           [1,1,0,1],
                           [1,0,1,0]])
A_to_power6 = matrix_power(input_array, 6)
sum_var = 0
for row in A_to_power6:
    for elem in row:
        sum_var += elem
int(sum_var/2)
# output is 557
#+end_example



* Question 2
Consider the following quote
#+BEGIN_QUOTE
"Undirected Graph can be considered as directed graph"
#+END_QUOTE
Prove it

Formally , Given an Undirected graph find a directed graph such that \( A_G = A_{G'}  \)


** Answer
Given An undirected graph mark it \( G=(V,E) \) and the adjacency matrix of his as \( A_G \)

Define the directed graph \(G'=(V',E')\) where \(V'=V\) and

\[ \forall e=(v_1,v_2)\in E : e_1=(v_1,v_2) , e_2=(v_2,v_1)\in E'  \]

The adjancey matrix of the directed graph is equal to the adjancey matrix of the undirected graph

\[ A_G=A_{G'} \]


* Question 3
Prove that given a directed graph \(G=(V,E)\) where \(V=(1,2,..,n)\) , let A be the adjacency matrix
\[ k \in \mathbb{N}\cup{\{0\}}: \forall i,j\in V : F(j,i ,k)=(A^k)_{i,j} \]
where \( F:V \times V \times \mathbb{N}\cup{\{0\}} \rightarrow \mathbb{N}\cup{\{0\}} \)
are all the walks from node j to i of length k

** Answer
We'll prove the theorem by induction
\begin{proof}
By induction

\underline{\textbf{Base Case:}}
For k = 1, \( A^k = A \), and there is a walk of length 1 between i and j
if and only if \(a_{ij} = 1\), thus the result holds.


\underline{\textbf{Step Case:}}
Assume the proposition holds for
\( k = n \) and consider the matrix \( A_{n+l} = A_nA \), By the inductive hypothesis, the
\( (i,j)^{th} \) entry of \( A_n \) counts the number of walks of length n between vertices i
and j. Now, the number of walks of length n + 1 between i and j equals the
number of walks of length n from vertex i to each vertex v that is adjacent to j.
But this is the \( (i,j)^{th} \) entry of \( A^nA = A^{n+1} \) the non-zero entries of the column
of A corresponding to v are precisely the first neighbours of v. Thus the result
follows by induction on n
\end{proof}

* Question 4
Find the number of possible walks of length 8 from 1 to 4 by the following undirected graph

#+BEGIN_SRC dot :file Question4_graph.png
digraph auth {
rankdir=LR;
node [shape=record];
1 [label="1"]
2 [label="2"]
3 [label="3"]
4 [label="4"]
1 -> 3
1 -> 4
2 -> 1
2 -> 3
3 -> 4
3 -> 1
4 -> 2

}
#+END_SRC


#+RESULTS:
[[file:Question4_graph.png]]
** Answer
We'll Write the adjancey matrix and calculate the \( A^8 \)

To do so we'll use the same code

#+name: calculate-question4-walks
#+ATTR_LATEX: :environment python
#+begin_example python :session :results value :exports both
import numpy
from numpy.linalg import matrix_power
input_array = numpy.array([[0,1,1,0],
                           [0,0,0,1],
                           [1,1,0,0],
                           [1,0,1,0]])
A_to_power6 = matrix_power(input_array, 8)
A_to_power6[3][0]
# output is 23
#+end_example

#+begin_src python :session :results value :exports none
import numpy
from numpy.linalg import matrix_power
input_array = numpy.array([[0,1,1,0],
                           [0,0,0,1],
                           [1,1,0,0],
                           [1,0,1,0]])
A_to_power6 = matrix_power(input_array, 8)
A_to_power6[3][0]
# output is 23
#+end_src

#+RESULTS:
: 23


To Calculate the Matrix by power of 8 we will use eigen values \( \det(A-\lambda I_n) = 0 \) lets apply the calculation
#+attr_latex: :mode math :environment vmatrix :math-prefix \det(A-\lambda I_n) = :math-suffix = 0
| -\lambda |        1 |        1 |        0 |
|        0 | -\lambda |        0 |        1 |
|        1 |        1 | -\lambda |        0 |
|        1 |        0 |        1 | -\lambda |

In order to find eigen value will python code
#+name: calculate-question4-walks-python
#+ATTR_LATEX: :environment python
#+begin_example python :session :results value :exports both
import numpy as np
from numpy.linalg import eig
input_array = np.array([[0,1,1,0],
                           [0,0,0,1],
                           [1,1,0,0],
                           [1,0,1,0]])
w,v=eig(input_array)

w # The vector of eigen values
# w = | 1.69 | -1 | +0.j | -0.347-1.028j |

#+end_example

#+begin_src python :session :results value :exports none
import numpy as np
from numpy.linalg import eig
input_array = np.array([[0,1,1,0],
                        [0,0,0,1],
                        [1,1,0,0],
                        [1,0,1,0]])
w,v=eig(input_array)
w # The vector of eigen values = | 1.69562077+0.j | -1 | +0.j | -0.34781038-1.02885225j |

#+end_src

#+RESULTS:
| 1.69562077+0.j | -1 | +0.j | -0.34781038+1.02885225j | -0.34781038-1.02885225j |

And finally we do
#+attr_latex: :mode math :environment pmatrix :math-prefix p^{-1}A^8p =
| \lambda^8_1 |           0 |           0 |           0 |
|           0 | \lambda^8_2 |           0 |           0 |
|           0 |           0 | \lambda^8_3 |           0 |
|           0 |           0 |           0 | \lambda^8_4 |


and change basis to get

#+attr_latex: :mode math :environment pmatrix :math-prefix A^8 =
| 19 | 23 | 18 | 13 |
| 13 | 14 | 13 | 10 |
| 18 | 23 | 19 | 13 |
| 23 | 26 | 23 | 14 |
* Question 5
Prove that the probablity to pass from vertex j to vertex i is given by
the matrix \( \tilde{A_G} = A_G*D^{-1}_G \)
where the matrix \( D_G \) is define to be

#+attr_latex: :mode math :environment pmatrix :math-prefix D_G =
| \deg(1) |       0 | ... |       0 |
|       0 | \deg(2) | ... |       0 |
|       0 |       0 | ... |       0 |
|       0 |       0 | ... | \deg(n) |



careful \( \tilde{A_G} \) might not be symmetric

** Answer

\begin{proof}
Since G is undirected graph and the probablity to travel from j to i is even distributed ,
the probability matrix is to divide the matrix \(A_G\) column j by \( \deg(j) \) for each \( j \in \mathbb{N}\cap [1,n] \)
or more formally
\[
\forall j \in \mathbb{N}\cap [1,n] \,, ( \hat{A_G} )_{i,j} := \frac{(A_G)_{i,j}}{\deg(j)}
\]

But Happily this is exactly equivalent to simply multiply the following matrix
\[
\tilde{A_G} = A_G*D^{-1}_G
\]
i.e
\[
\tilde{A_G} = \hat{A_G}
\]
Which is what we want it to be
\end{proof}


* Question 6
let \(p^{(0)}\in \mathbb{R} \) be the initial probability distribution of the graph

let \(p^{(n)} \in \mathbb{R}\) be the distribution of the graph after n walks

prove that
\[
p^{(n)} = \tilde{A_G^n} * p^{( 0 )}
\]



** Answer
\begin{proof}
Given a vertex j and vertex i we first want to find all possible walks from j to i with length n ,

We have already proven that the number of possible walks are \( ( A_G^n )_{i,j} \)

In order to get the required probability we need to find the sum of all walks from j to any vertex i.e
\[
\sigma _j = \sum _{i\in V} ( A_G )_{i,j}^{n}
\]

\[
( Prob )_{i,j} = \frac{(A_G^n)_{i,j}} { \sigma _j }
\]

Ultimately , I have proven that the probability of walking n walks from vertex j to i is simply
\( \tilde{A}^n \)

\end{proof}

Note that we are not yet done we still have to prove that
\[
p^{(n)} = \tilde{A}^n * p^{(0)}
\]

To skip to that click [[final-prove][final]]

Another proof is by induction

\begin{proof}
\( \tilde{A}^{m+1} = \tilde{A} * \tilde{A}^{m}\)

\underline{\textbf{Base Case:}}
for n=0 we have \(\tilde{A} = \tilde{A}\)

\underline{\textbf{Step Case:}}
Given that the claim is true for \(n\in \mathbb{N}\) we will prove it for \(n+1\) ,
more specificly given j and i we are searching for the probablity of going from j to i  after \(n+1\) walks

Since by assumption we already know the probabilty of walking n long from j to any \(v\in V\)
 which is \( (A_G^n)_{v,j} \) and also
we know the probablity of getting from any vertex v into vertex i which is \( ( A_G )_{i,v}  \)

The probabilty of getting from j to i after n+1 walks is by conditional probabilty

\[ Prob^{(n+1)} =  \sum_{v\in V} (A_G)_{i,v}*(A_G^n)_{v,j}\]
since
\[
P(B) = \sum_{i} P(B|A_i) \,, \sum _{i} P(A_i) = 1
\]

This equation is nothing but \( \tilde{A}^{m+1} = \tilde{A} * \tilde{A}^{m}\)
\end{proof}

Now Given a vertices \(i \in V\) by the complete probability theorem the probability of getting into vertex i is
\[ p^{(n)}_i = \sum_{v \in V} \tilde{A}_{i,v}*p^{(0)}_v \]
But this equation is nothing but what we needed to prove which is
#+NAME: final-prove
\begin{equation}
p^{(n)} = \tilde{A}^n * p^{(0)}
\end{equation}



* Question 7
Prove that \( \tilde{A} \) is diagolizable over \( \mathbb{R} \)

** Answer
We will use the spectral theory for the prove

[[https://en.wikipedia.org/wiki/Spectral_theory][Spectral Theory]]

\begin{math}
\underline{\textbf{Reminder:}}
\end{math}
Please Note that \( \tilde{A}=A_G*D^{-1}\)

By assumption , we know A is a symmetric matrix ,

lets mark the matrix
\[ Q\in \mathbb{M}_n(\mathbb{R}) : Q := \diag(\sqrt{ \deg(v_1) },\dots , \sqrt{ \deg(v_n)) } \]

Observe the following logic:

\[
Q^{-1}*\tilde{A}*Q=Q^{-1}*A*D^{-1}*Q=Q^{-1}*A*Q^{-1}
\]
where \(A=A^{t}\)

\begin{align*}
(Q^{-1}*A*Q^{-1})^{t}&=(A*Q^{-1})^t*(Q^{-1})^t= \\
                    &=(Q^{-1})^t*A^t*(Q^{-1})^t \\
                    &=(Q^{-1})^t*A*(Q^{-1})^t \\
                    &=Q^{-1}*A*Q^{-1}
\end{align*}
By this equation we can infer that the matrix

\(Q^{-1}*\tilde{A}*Q\) is
a symmetric matrix which means that we can use on it the spectral theory

\[
\exists P\in \mathbb{M}_n(\mathbb{R}) : P^{-1}*(Q^{-1}*\tilde{A}*Q)*P = \diag(\lambda _1 , \lambda _2 , \dots , \lambda _n)
\]
\[
=(QP)^{-1}\tilde{A}QP
\]

So I have found a matrix QP which diagolize the matrix \(\tilde{A}\)






* Question 8

let \(\lambda\) be an eigen value of \(\tilde{A}\) proof that
\(\lambda\in [-1,1]\)

** Answer
I'll prove it by contradiction , on the matrix \(\tilde{A}^t\), let \(\lambda\) be eigen value of \(\tilde{A}\)
\[\exists v\in V : \tilde{A}v=\lambda v\]
for some \(\lambda > 1 \)

Since the row of the matrix \(\tilde{A}^t\) sums to 1 , each element of \(\tilde{A}^tx\) is an
[[https://en.wikipedia.org/wiki/Convex_combination][convex combination]] of the components of x , which can't be greater than a \(x_{max}\) where \(x_{max}\) is the maxium
element of the vector x .

Let's see it formally

\[
x_{max} := \max_{j\in\mathbb{N}\cap [1,n]}{|x_j|}
\]
\[
\alpha := \tilde{A}^t
\]
\[
\forall \mathbb{N}\cap [1,n] \sum_{j=1}^{n} \alpha_{ij} = 1
\]
\begin{align*}
\forall x\in \mathbb{R}^{n} \,, \forall i\in\mathbb{N}\cap [1,n]  \,, \sum_{j=1}^n\alpha _{ij} x_{j}  &\leq\sum_{j=1}^n \alpha_{ij}x_{max}= \\
                                                                    &=x_{max} \sum_{j=1}^{n} \alpha_{ij} = x_{max}
\end{align*}
In conclusion

#+name: label-equ1
\begin{equation}
(\tilde{A}^t x)_{max} \leq x_{max}
\end{equation}

On the other hand , At least one element of \(\lambda x \) is greater than \(x_{max}\) , which proves that
\(\lambda > 1\) is impossible

Or , more precisely , let \(\lambda > 1\) be an eigen value of the matrix
\(\tilde{A}^t\) and let \(v_{\lambda}\) be the normalized eigen vector of
eigen value \(\lambda\) then

#+name: label-equ2
\begin{equation}
(v_{\lambda})_{max} <
\lambda (v_{\lambda})_{max} =
( \lambda v_{\lambda} )_{max} =
( \tilde{A}^t v_{\lambda} )_{max}
\end{equation}

By equation [[label-equ1]] we can select \(x:=v_{\lambda}\) and we'll have
\(
(\tilde{A}^t v_{\lambda})_{max} \leq (v_{\lambda})_{max}
\) which contradict equation [[label-equ2]]





* Introduction
#+BEGIN_COMMENT
Kruskal's algorithm[1] finds a minimum spanning forest of an undirected edge-weighted graph. If the graph is connected, it finds a minimum spanning tree. (A minimum spanning tree of a connected graph is a subset of the edges that forms a tree that includes every vertex, where the sum of the weights of all the edges in the tree is minimized. For a disconnected graph, a minimum spanning forest is composed of a minimum spanning tree for each connected component.) It is a greedy algorithm in graph theory as in each step it adds the next lowest-weight edge that will not form a cycle to the minimum spanning forest.[2]



This algorithm first appeared in Proceedings of the American Mathematical Society, pp. 48–50 in 1956, and was written by Joseph Kruskal.[3] It was rediscovered by Loberman & Weinberger (1957).[4]

Other algorithms for this problem include Prim's algorithm, the reverse-delete algorithm, and Borůvka's algorithm.

#+END_COMMENT

* TODO Simple pseudo code :ATTACH:
:PROPERTIES:
:ID:       5676580d-8e54-46e4-a795-a8a7fddd3c7c
:END:
- Note taken on [2023-07-05 Wed 14:42] \\
  Hello World !!!
- Note taken on [2023-07-05 Wed 14:37] \\
  BARAKKKK
- Note taken on [2023-07-05 Wed 14:36] \\
  Hello World !!
- Note taken on [2023-07-05 Wed 14:36] \\
  Barak the King
Hello World
\begin{displaymath}
\lambda *6
\end{displaymath}

0:00:23
0:01:17
0:01:20
0:01:22
[[https://orgmode.org/org.html#Tables-in-LaTeX-export][The Org Manual]]
0:01:22

0:01:22
0:01:22
0:01:22
0:01:22 0:01:22 0:01:22 0:01:22 0:01:22
0:00:03 0:00:05 0:00:07 0:00:08 0:00:09 0:00:09 0:00:00 0:00:03 0:00:04
0:00:06 0:00:07 0:00:00 0:00:00 0:00:02 0:00:03 0:00:02 0:00:03

#+BEGIN_COMMENT


Here is some code

This is some random text




#+begin_mdframed
\begin{algorithmic}
\State $i \gets 10$
\If{$i\geq 5$}
    \State $i \gets i-1$
\Else
    \If{$i\leq 3$}
        \State $i \gets i+2$
    \EndIf
\EndIf
\end{algorithmic}
#+end_mdframed

bla bla bla


Another Example , please note the following


\begin{algorithm}
\caption{An algorithm with caption}\label{alg:cap}
\begin{algorithmic}
\Require $n \geq 0$
\Ensure $y = x^n$
\State $y \gets 1$
\State $X \gets x$
\State $N \gets n$
\While{$N \neq 0$}
\If{$N$ is even}
    \State $X \gets X \times X$
    \State $N \gets \frac{N}{2}$  \Comment{This is a comment}
\ElsIf{$N$ is odd}
    \State $y \gets y \times X$
    \State $N \gets N - 1$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

#+END_COMMENT
* IDEA
* KILL
* IDEA
